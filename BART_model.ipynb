{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BART MODEL TRAINING**"
      ],
      "metadata": {
        "id": "gOupqkEzc1_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prepare and split the extracted data for Training**"
      ],
      "metadata": {
        "id": "lDXL5AzxR2p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/discharge_summary_generation/dataset_creation/data_preparation.py\""
      ],
      "metadata": {
        "id": "FMVco2PoQFCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/discharge_summary_generation/discharge_summary_generation-main/dataset_creation/data_split.py\""
      ],
      "metadata": {
        "id": "lghfOQ1GQFsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHH4s6cd4gyg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/mimic-iii_discharge_summary.csv\")\n",
        "data = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY1qYfJo42Ic",
        "outputId": "6a429c74-b4e9-4459-c758-7e0581c3e5a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'hadm_id', 'input_text', 'output_text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22mrW9kD42v_"
      },
      "outputs": [],
      "source": [
        "is_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAigyIvm453e",
        "outputId": "c6f110c6-4915-4dd1-e2d6-4d5dedc1487d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.1-py3-none-any.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.1 dill-0.3.7 multiprocess-0.70.15 xxhash-3.2.0\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=d139d78c88b134e2dc470d85fa2e44c8d02738ad6f73965fdb1914a4752305bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting transformers==4.5.0\n",
            "  Downloading transformers-4.5.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.0) (3.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.0) (1.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.0) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.0) (2.27.1)\n",
            "Collecting sacremoses (from transformers==4.5.0)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.5.0)\n",
            "  Downloading tokenizers-0.10.3.tar.gz (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.0) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.0) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.5.0) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.5.0) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.5.0) (1.3.1)\n",
            "Building wheels for collected packages: tokenizers, sacremoses\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895239 sha256=1f967ef96b7dae4fd48035a6015bd5511e8a0f84c3b56313af5cfde393072128\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Failed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "if is_colab:\n",
        "    !pip install datasets\n",
        "    !pip install rouge_score\n",
        "    !pip install transformers==4.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15g3mMiJ7c0f",
        "outputId": "51479054-5a7b-4604-a487-19cec60b739b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2.3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: xxhash in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (2023.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: responses<0.19 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
            "fatal: destination path 'BART-MIMIC-CXR' already exists and is not an empty directory.\n",
            "Requirement already satisfied: datasets>=1.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from -r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (2.3.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from -r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 2)) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from -r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 3)) (3.20.3)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 848 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 4.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting py7zr\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.3 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: responses<0.19 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (2023.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (3.8.4)\n",
            "Requirement already satisfied: dill<0.3.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (0.3.5.1)\n",
            "Requirement already satisfied: xxhash in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: multiprocess in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (0.14.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sacrebleu>=1.4.12->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: portalocker in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sacrebleu>=1.4.12->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: regex in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sacrebleu>=1.4.12->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 4)) (2023.5.5)\n",
            "Requirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sacrebleu>=1.4.12->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 4)) (0.4.6)\n",
            "Collecting lxml\n",
            "  Downloading lxml-4.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 70.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rouge-score->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rouge-score->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: joblib in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from nltk->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from nltk->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 6)) (8.1.3)\n",
            "Collecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 44.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting brotli>=1.0.9; platform_python_implementation == \"CPython\"\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 68.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.9 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 73.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: psutil; sys_platform != \"cygwin\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from py7zr->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 7)) (5.9.5)\n",
            "Collecting inflate64>=0.3.1; python_version > \"3.6\"\n",
            "  Downloading inflate64-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[K     |████████████████████████████████| 412 kB 75.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from responses<0.19->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (1.26.16)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (4.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->datasets>=1.1.3->-r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt (line 1)) (2.8.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=7a96999b247a93f1c94d0b906c8692c35d860c02e2bcda3f80cdc038be3962d5\n",
            "  Stored in directory: /home/azureuser/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: lxml, sacrebleu, nltk, rouge-score, pycryptodomex, brotli, multivolumefile, pybcj, pyppmd, inflate64, texttable, pyzstd, py7zr\n",
            "Successfully installed brotli-1.0.9 inflate64-0.3.1 lxml-4.9.3 multivolumefile-0.2.3 nltk-3.8.1 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 rouge-score-0.1.2 sacrebleu-2.3.1 texttable-1.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!git clone https://github.com/Shaumik-Ashraf/BART-MIMIC-CXR.git\n",
        "!pip install -r /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNNzjIIA7c0m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import BartModel, BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzShYEk_7c0n"
      },
      "outputs": [],
      "source": [
        "directory = r'/home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenize and preprocess data  to feed into model**"
      ],
      "metadata": {
        "id": "2pClMyAePmrA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XORACPz77c0o"
      },
      "outputs": [],
      "source": [
        "def load_file(filename):\n",
        "\tprint(f\"Loading data from {filename}...\");\n",
        "\tdf = pd.read_csv(filename)\n",
        "\tprint(f\"Done.\");\n",
        "\treturn( np.array(df) );\n",
        "\n",
        "def load_bart(model_name='facebook/bart-large-cnn', tokenizer_name='facebook/bart-large-cnn'):\n",
        "\tprint(f\"Loading pretrained model {model_name}...\");\n",
        "\tmodel = bartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\tprint(\"Done.\");\n",
        "\tprint(f\"Loading pretrained tokenizer {tokenizer_name}...\");\n",
        "\ttokenizer = bartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\tprint(\"Done.\");\n",
        "\treturn((model, tokenizer));\n",
        "\n",
        "def basebart(article_to_summarize, model, tokenizer):\n",
        "\tinputs = tokenizer([article_to_summarize], max_length=1024, return_tensors='pt')\n",
        "\tinputs.to(device)\n",
        "\tsummary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=25, early_stopping=True)\n",
        "\treturn [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
        "\n",
        "def write_csv_row(opened_file, row, model, tokenizer):\n",
        "\tcomp_summary = basebart(row[2], model, tokenizer)\n",
        "\topened_file.write(f\"\\\"{row[0]}\\\",\\\"{row[1]}\\\",\\\"{comp_summary}\\\",\\\"{row[3]}\\\"\\n\");\n",
        "\treturn(comp_summary);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRqQ3lKr7c0p"
      },
      "outputs": [],
      "source": [
        "TEST_FILE = '/home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/test_small.csv'\n",
        "LIMIT = -1\n",
        "SUMMARIES_FILE = '/home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/' + str(LIMIT) + '.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG-TEPvy7c0q"
      },
      "outputs": [],
      "source": [
        "print(\"==================== Start abstractive summarization ======================\");\n",
        "\n",
        "data = load_file(TEST_FILE);\n",
        "model, tokenizer = load_bart();\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Writing {os.path.basename(SUMMARIES_FILE)}...\");\n",
        "f = open(SUMMARIES_FILE, 'w');\n",
        "f.write(f\"\\\"subject_id\\\",\\\"study_id\\\",\\\"prediction\\\",\\\"actual\\\"\\n\");\n",
        "i = 0;\n",
        "if LIMIT==-1: # based on the limit, print progress messages appropriately\n",
        "\tfor row in data:\n",
        "\t\twrite_csv_row(f, row, model, tokenizer);\n",
        "\t\tif( (i%1000 == 0) or (i+1 == LIMIT) ):\n",
        "\t\t\tprint(f\"Computed {i+1} summaries\");\n",
        "\t\ti += 1;\n",
        "elif LIMIT < 100:\n",
        "\tfor row in data[:LIMIT]:\n",
        "\t\twrite_csv_row(f, row, model, tokenizer);\n",
        "\t\tif( (i%(int(LIMIT/4)) == 0) or (i+1 == LIMIT)):\n",
        "\t\t\tprint(f\"Computed {i+1} summaries\");\n",
        "\t\ti += 1;\n",
        "else:\n",
        "\tfor row in data[:LIMIT]:\n",
        "\t\twrite_csv_row(f, row, model, tokenizer);\n",
        "\t\tif( (i%(int(LIMIT/8)) == 0) or (i+1 == LIMIT) ):\n",
        "\t\t\tprint(f\"Computed {i+1} summaries\");\n",
        "\t\ti += 1;\n",
        "\n",
        "f.close();\n",
        "print(\"Done.\\n\");\n",
        "print(\"==================== End abstractive summarization ======================\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jgBN3b47c0r",
        "outputId": "861f3c82-5a36-4879-9eec-ea51721d3ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-02 06:14:53.803718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-02 06:15:08.426711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-08-02 06:15:08.426954: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-08-02 06:15:08.426974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "08/02/2023 06:15:18 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
            "08/02/2023 06:15:18 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=0,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output_small/runs/Aug02_06-15-16_kaviyasampoornam1,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=output_small,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['azure_ml', 'mlflow', 'tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output_small,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "08/02/2023 06:15:19 - WARNING - datasets.builder -   Using custom data configuration default-41914e550bd5bbb4\n",
            "Downloading and preparing dataset csv/default to /home/azureuser/.cache/huggingface/datasets/csv/default-41914e550bd5bbb4/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
            "Downloading data files: 100%|██████████████████| 3/3 [00:00<00:00, 12972.07it/s]\n",
            "Extracting data files: 100%|██████████████████████| 3/3 [00:00<00:00, 69.05it/s]\n",
            "Dataset csv downloaded and prepared to /home/azureuser/.cache/huggingface/datasets/csv/default-41914e550bd5bbb4/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 121.13it/s]\n",
            "https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/azureuser/.cache/huggingface/transformers/tmphaa43fzd\n",
            "Downloading: 100%|█████████████████████████| 1.55k/1.55k [00:00<00:00, 8.27MB/s]\n",
            "storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json in cache at /home/azureuser/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "creating metadata file for /home/azureuser/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /home/azureuser/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-large-cnn\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /home/azureuser/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-large-cnn\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/azureuser/.cache/huggingface/transformers/tmpuej0t_us\n",
            "Downloading: 100%|███████████████████████████| 878k/878k [00:00<00:00, 2.42MB/s]\n",
            "storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json in cache at /home/azureuser/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "creating metadata file for /home/azureuser/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /home/azureuser/.cache/huggingface/transformers/tmpv7uwqop3\n",
            "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 1.20MB/s]\n",
            "storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt in cache at /home/azureuser/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "creating metadata file for /home/azureuser/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /home/azureuser/.cache/huggingface/transformers/tmphsdkl15f\n",
            "Downloading: 100%|█████████████████████████| 1.29M/1.29M [00:00<00:00, 7.01MB/s]\n",
            "storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json in cache at /home/azureuser/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "creating metadata file for /home/azureuser/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /home/azureuser/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /home/azureuser/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json from cache at /home/azureuser/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /home/azureuser/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-large-cnn\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/azureuser/.cache/huggingface/transformers/tmpq7vhaaum\n",
            "Downloading: 100%|█████████████████████████| 1.51G/1.51G [00:17<00:00, 90.9MB/s]\n",
            "storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin in cache at /home/azureuser/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "creating metadata file for /home/azureuser/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /home/azureuser/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "08/02/2023 06:15:47 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7f79e57b90d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25ba/s]\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.59ba/s]\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93ba/s]\n",
            "Downloading builder script: 5.60kB [00:00, 13.4MB/s]                            \n",
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 350\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 132\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "100%|███████████████████████████████████████| 132/132 [1:08:37<00:00, 29.68s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Attempted to log scalar metric train_runtime:\n",
            "4120.2784\n",
            "Attempted to log scalar metric train_samples_per_second:\n",
            "0.255\n",
            "Attempted to log scalar metric train_steps_per_second:\n",
            "0.032\n",
            "Attempted to log scalar metric total_flos:\n",
            "2218319378841600.0\n",
            "Attempted to log scalar metric train_loss:\n",
            "2.6489886659564394\n",
            "Attempted to log scalar metric epoch:\n",
            "3.0\n",
            "08/02/2023 07:26:33 - WARNING - urllib3.connectionpool -   Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='centralindia.api.azureml.ms', port=443): Read timed out. (read timeout=120)\")': /mlflow/v2.0/subscriptions/e8217ddd-bc7b-440f-9154-862bb9ec5400/resourceGroups/rg001/providers/Microsoft.MachineLearningServices/workspaces/project/api/2.0/mlflow/runs/log-batch\n",
            "{'train_runtime': 4120.2784, 'train_samples_per_second': 0.255, 'train_steps_per_second': 0.032, 'train_loss': 2.6489886659564394, 'epoch': 3.0}\n",
            "100%|███████████████████████████████████████| 132/132 [1:10:40<00:00, 32.13s/it]\n",
            "Saving model checkpoint to output_small\n",
            "Configuration saved in output_small/config.json\n",
            "Model weights saved in output_small/pytorch_model.bin\n",
            "tokenizer config file saved in output_small/tokenizer_config.json\n",
            "Special tokens file saved in output_small/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =      2.649\n",
            "  train_runtime            = 1:08:40.27\n",
            "  train_samples            =        350\n",
            "  train_samples_per_second =      0.255\n",
            "  train_steps_per_second   =      0.032\n",
            "08/02/2023 07:26:56 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 8\n",
            "100%|█████████████████████████████████████████████| 7/7 [02:33<00:00, 20.86s/it]Attempted to log scalar metric eval_loss:\n",
            "3.077890634536743\n",
            "Attempted to log scalar metric eval_rouge1:\n",
            "21.0431\n",
            "Attempted to log scalar metric eval_rouge2:\n",
            "8.2769\n",
            "Attempted to log scalar metric eval_rougeL:\n",
            "18.5173\n",
            "Attempted to log scalar metric eval_rougeLsum:\n",
            "18.8056\n",
            "Attempted to log scalar metric eval_gen_len:\n",
            "25.0\n",
            "Attempted to log scalar metric eval_runtime:\n",
            "186.6087\n",
            "Attempted to log scalar metric eval_samples_per_second:\n",
            "0.268\n",
            "Attempted to log scalar metric eval_steps_per_second:\n",
            "0.038\n",
            "Attempted to log scalar metric epoch:\n",
            "3.0\n",
            "100%|█████████████████████████████████████████████| 7/7 [02:34<00:00, 22.09s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_gen_len            =       25.0\n",
            "  eval_loss               =     3.0779\n",
            "  eval_rouge1             =    21.0431\n",
            "  eval_rouge2             =     8.2769\n",
            "  eval_rougeL             =    18.5173\n",
            "  eval_rougeLsum          =    18.8056\n",
            "  eval_runtime            = 0:03:06.60\n",
            "  eval_samples            =         50\n",
            "  eval_samples_per_second =      0.268\n",
            "  eval_steps_per_second   =      0.038\n",
            "08/02/2023 07:30:04 - INFO - __main__ -   *** Test ***\n",
            "***** Running Prediction *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "100%|███████████████████████████████████████████| 13/13 [05:30<00:00, 25.05s/it]***** test metrics *****\n",
            "  test_gen_len            =       25.0\n",
            "  test_loss               =     3.1513\n",
            "  test_rouge1             =    21.1296\n",
            "  test_rouge2             =     8.2803\n",
            "  test_rougeL             =    18.8755\n",
            "  test_rougeLsum          =    19.0653\n",
            "  test_runtime            = 0:05:58.92\n",
            "  test_samples            =        100\n",
            "  test_samples_per_second =      0.279\n",
            "  test_steps_per_second   =      0.036\n",
            "100%|███████████████████████████████████████████| 13/13 [05:31<00:00, 25.46s/it]\n",
            "08/02/2023 07:38:04 - WARNING - urllib3.connectionpool -   Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='centralindia.api.azureml.ms', port=443): Read timed out. (read timeout=120)\")': /mlflow/v2.0/subscriptions/e8217ddd-bc7b-440f-9154-862bb9ec5400/resourceGroups/rg001/providers/Microsoft.MachineLearningServices/workspaces/project/api/2.0/mlflow/runs/update\n"
          ]
        }
      ],
      "source": [
        "!python /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/bart/transformers/seq2seq/run_summarization.py --model_name facebook/bart-large-cnn --tokenizer_name facebook/bart-large-cnn --output_dir output_small --train_file /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/train_small.csv --validation_file /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/val_small.csv --test_file /home/azureuser/cloudfiles/code/Users/kaviyasampoornam/discharge_summary_generation-main/test_small.csv --text_column input_text --summary_column output_text --max_source_length 1024 --max_target_length 25 --num_beams 4 --do_train --do_eval --do_predict --predict_with_generate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save model to load and use**"
      ],
      "metadata": {
        "id": "PNtFGceuTFLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,\"model.pth\")"
      ],
      "metadata": {
        "id": "UigLHSFjdM3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/model/\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/model/\")"
      ],
      "metadata": {
        "id": "IUjguHdmTPoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "model_path = '/content/drive/MyDrive/model/'\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(model_path)\n",
        "model2 = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "rIe81G-kTeMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Chunking**"
      ],
      "metadata": {
        "id": "RXqp9LOAUbpn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9_EYJkyftb3",
        "outputId": "f3c26e08-d093-4b94-9607-61ffb6bee1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "A female with a history of emphysema, diagnosed by her primary care doctor and diagnosed with COPD flares, was admitted My daughter requires medication to maintain a higher oxygen saturation level than 90%. She has been on nebulizers and levofloxacin The condition can be attributed to om complaints, neurologic changes, rashes, palpitations, and orthopnea. It The elderly female described in the article had a symptomatic history of lightheadedness and headache, but the study revealed that Norvasc had a The CPAP machine makes it difficult to assess the exam, and there is no evidence of jugular venous pressure. The neck exam is The patient was admitted to the Medical Intensive Care Unit for COPD/dyspnea/pneumonia. She was given The patient underwent chest PT and had to use nebulizers for approximately 0.5 h (100 mL) due to persistent Dr. was given a rigid bronchoscopy with general anesthesia, where a stem of 12 x 25 and a portion of the The Interventional Pulmonology service examined the patient again and determined that she appeared much better. They advised her to undergo pulmonary rehabilitation and followup checks within The patient's outpatient regimen involved controlling her urination and maintaining blood pressure levels, while also receiving diltiazem and The induced steroid treatment was effective, and her glucose levels returned to normal after cooling. Resulted in a six-day course of levofloxacin 500 p.o. q.d., which was The patient's symptoms were blunted during the hospital course, and she appeared to be clinically depressed during that time. She was given proton The patient was kept in communication with her husband and throughout the course of the course. Despite experiencing severe muscle weakness, she was able to sit in  The patient's extremities were found to be weak at the knee, ankle, elbows, and hips, suggesting that the weakness was probably due to The patient had a genate that was 93% pure room air and had no tachycardic symptoms. She was also in good physical Until the patient can be euthanized and can no longer use the drugs, SubQ Heparin 5000 units subcutaneous b. The patient is advised to complete a seven-day course with a dosage of 500 mg of levofloxacin p.o. within The final diagnoses include tracheomalacia, hypertension, hypothyroidism, restrictive lung defect, and depression.\n"
          ]
        }
      ],
      "source": [
        "def long_text(input_sentence, max_length=512, max_new_tokens=32):\n",
        "    # Split the input text into smaller segments with a specified maximum length\n",
        "    device = \"cpu\"\n",
        "    segments = [input_sentence[i:i + max_length] for i in range(0, len(input_sentence), max_length)]\n",
        "    print(len(segments))\n",
        "    # Generate for each segment separately\n",
        "    generated_sentences = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        batch = tokenizer2(\"paraphrase: \" + segment if i > 0 else segment,\n",
        "                          return_tensors='pt',\n",
        "                          truncation=True,\n",
        "                          padding=True,\n",
        "                          max_length=max_length)\n",
        "        batch = batch.to(device)\n",
        "        generated_ids = model2.generate(batch.input_ids, max_new_tokens=max_new_tokens)\n",
        "        generated_sentence = tokenizer2.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "        generated_sentences.append(generated_sentence[0])\n",
        "\n",
        "    # Concatenate the generated text\n",
        "    final_generated_sentence = \" \".join(generated_sentences)\n",
        "    return final_generated_sentence\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/Book1.csv\")\n",
        "input_sentence = data.input[0]\n",
        "result = long_text(input_sentence)\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}